{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root_path = './'\n",
    "stat_path = osp.join(root_path, 'statistics')\n",
    "setup_file = osp.join(stat_path, 'setup.txt')\n",
    "camera_file = osp.join(stat_path, 'camera.txt')\n",
    "performer_file = osp.join(stat_path, 'performer.txt')\n",
    "replication_file = osp.join(stat_path, 'replication.txt')\n",
    "label_file = osp.join(stat_path, 'label.txt')\n",
    "skes_name_file = osp.join(stat_path, 'skes_available_name.txt')\n",
    "\n",
    "denoised_path = osp.join(root_path, 'denoised_data')\n",
    "raw_skes_joints_pkl = osp.join(denoised_path, 'raw_denoised_joints.pkl')\n",
    "frames_file = osp.join(denoised_path, 'frames_cnt.txt')\n",
    "\n",
    "save_path = './'\n",
    "\n",
    "\n",
    "if not osp.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "\n",
    "def remove_nan_frames(ske_name, ske_joints, nan_logger):\n",
    "    num_frames = ske_joints.shape[0]\n",
    "    valid_frames = []\n",
    "\n",
    "    for f in range(num_frames):\n",
    "        if not np.any(np.isnan(ske_joints[f])):\n",
    "            valid_frames.append(f)\n",
    "        else:\n",
    "            nan_indices = np.where(np.isnan(ske_joints[f]))[0]\n",
    "            nan_logger.info('{}\\t{:^5}\\t{}'.format(ske_name, f + 1, nan_indices))\n",
    "\n",
    "    return ske_joints[valid_frames]\n",
    "\n",
    "def seq_translation(skes_joints):\n",
    "    for idx, ske_joints in enumerate(skes_joints):\n",
    "        num_frames = ske_joints.shape[0]\n",
    "        num_bodies = 1 if ske_joints.shape[1] == 75 else 2\n",
    "        if num_bodies == 2:\n",
    "            missing_frames_1 = np.where(ske_joints[:, :75].sum(axis=1) == 0)[0]\n",
    "            missing_frames_2 = np.where(ske_joints[:, 75:].sum(axis=1) == 0)[0]\n",
    "            cnt1 = len(missing_frames_1)\n",
    "            cnt2 = len(missing_frames_2)\n",
    "\n",
    "        i = 0  # get the \"real\" first frame of actor1\n",
    "        while i < num_frames:\n",
    "            if np.any(ske_joints[i, :75] != 0):\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        origin = np.copy(ske_joints[i, 3:6])  # new origin: joint-2\n",
    "\n",
    "        for f in range(num_frames):\n",
    "            if num_bodies == 1:\n",
    "                ske_joints[f] -= np.tile(origin, 25)\n",
    "            else:  # for 2 actors\n",
    "                ske_joints[f] -= np.tile(origin, 50)\n",
    "\n",
    "        if (num_bodies == 2) and (cnt1 > 0):\n",
    "            ske_joints[missing_frames_1, :75] = np.zeros((cnt1, 75), dtype=np.float32)\n",
    "\n",
    "        if (num_bodies == 2) and (cnt2 > 0):\n",
    "            ske_joints[missing_frames_2, 75:] = np.zeros((cnt2, 75), dtype=np.float32)\n",
    "\n",
    "        skes_joints[idx] = ske_joints  # Update\n",
    "\n",
    "    return skes_joints\n",
    "\n",
    "\n",
    "def frame_translation(skes_joints, skes_name, frames_cnt):\n",
    "    nan_logger = logging.getLogger('nan_skes')\n",
    "    nan_logger.setLevel(logging.INFO)\n",
    "    nan_logger.addHandler(logging.FileHandler(\"./nan_frames.log\"))\n",
    "    nan_logger.info('{}\\t{}\\t{}'.format('Skeleton', 'Frame', 'Joints'))\n",
    "\n",
    "    for idx, ske_joints in enumerate(skes_joints):\n",
    "        num_frames = ske_joints.shape[0]\n",
    "        # Calculate the distance between spine base (joint-1) and spine (joint-21)\n",
    "        j1 = ske_joints[:, 0:3]\n",
    "        j21 = ske_joints[:, 60:63]\n",
    "        dist = np.sqrt(((j1 - j21) ** 2).sum(axis=1))\n",
    "\n",
    "        for f in range(num_frames):\n",
    "            origin = ske_joints[f, 3:6]  # new origin: middle of the spine (joint-2)\n",
    "            if (ske_joints[f, 75:] == 0).all():\n",
    "                ske_joints[f, :75] = (ske_joints[f, :75] - np.tile(origin, 25)) / \\\n",
    "                                      dist[f] + np.tile(origin, 25)\n",
    "            else:\n",
    "                ske_joints[f] = (ske_joints[f] - np.tile(origin, 50)) / \\\n",
    "                                 dist[f] + np.tile(origin, 50)\n",
    "\n",
    "        ske_name = skes_name[idx]\n",
    "        ske_joints = remove_nan_frames(ske_name, ske_joints, nan_logger)\n",
    "        frames_cnt[idx] = num_frames  # update valid number of frames\n",
    "        skes_joints[idx] = ske_joints\n",
    "\n",
    "    return skes_joints, frames_cnt\n",
    "\n",
    "\n",
    "def align_frames(skes_joints, frames_cnt):\n",
    "    \"\"\"\n",
    "    Align all sequences with the same frame length.\n",
    "\n",
    "    \"\"\"\n",
    "    num_skes = len(skes_joints)\n",
    "    max_num_frames = frames_cnt.max()  # 300\n",
    "    aligned_skes_joints = np.zeros((num_skes, max_num_frames, 150), dtype=np.float32)\n",
    "\n",
    "    for idx, ske_joints in enumerate(skes_joints):\n",
    "        num_frames = ske_joints.shape[0]\n",
    "        num_bodies = 1 if ske_joints.shape[1] == 75 else 2\n",
    "        if num_bodies == 1:\n",
    "            aligned_skes_joints[idx, :num_frames] = np.hstack((ske_joints,\n",
    "                                                               np.zeros_like(ske_joints)))\n",
    "        else:\n",
    "            aligned_skes_joints[idx, :num_frames] = ske_joints\n",
    "\n",
    "    return aligned_skes_joints\n",
    "\n",
    "\n",
    "def one_hot_vector(labels):\n",
    "    num_skes = len(labels)\n",
    "    labels_vector = np.zeros((num_skes, 60))\n",
    "    for idx, l in enumerate(labels):\n",
    "        labels_vector[idx, l] = 1\n",
    "\n",
    "    return labels_vector\n",
    "\n",
    "\n",
    "def split_train_val(train_indices, method='sklearn', ratio=0.05):\n",
    "    \"\"\"\n",
    "    Get validation set by splitting data randomly from training set with two methods.\n",
    "    In fact, I thought these two methods are equal as they got the same performance.\n",
    "\n",
    "    \"\"\"\n",
    "    if method == 'sklearn':\n",
    "        return train_test_split(train_indices, test_size=ratio, random_state=10000)\n",
    "    else:\n",
    "        np.random.seed(10000)\n",
    "        np.random.shuffle(train_indices)\n",
    "        val_num_skes = int(np.ceil(0.05 * len(train_indices)))\n",
    "        val_indices = train_indices[:val_num_skes]\n",
    "        train_indices = train_indices[val_num_skes:]\n",
    "        return train_indices, val_indices\n",
    "\n",
    "\n",
    "def split_dataset(skes_joints, label, performer, camera, evaluation, save_path):\n",
    "    train_indices, test_indices = get_indices(performer, camera, evaluation)\n",
    "    m = 'sklearn'  # 'sklearn' or 'numpy'\n",
    "    # Select validation set from training set\n",
    "    train_indices, val_indices = split_train_val(train_indices, m)\n",
    "\n",
    "    # Save labels and num_frames for each sequence of each data set\n",
    "    train_labels = label[train_indices]\n",
    "    val_labels = label[val_indices]\n",
    "    test_labels = label[test_indices]\n",
    "\n",
    "    # Save data into a .h5 file\n",
    "    h5file = h5py.File(osp.join(save_path, 'NTU_%s.h5' % (evaluation)), 'w')\n",
    "    # Training set\n",
    "    h5file.create_dataset('x', data=skes_joints[train_indices])\n",
    "    train_one_hot_labels = one_hot_vector(train_labels)\n",
    "    h5file.create_dataset('y', data=train_one_hot_labels)\n",
    "    # Validation set\n",
    "    h5file.create_dataset('valid_x', data=skes_joints[val_indices])\n",
    "    val_one_hot_labels = one_hot_vector(val_labels)\n",
    "    h5file.create_dataset('valid_y', data=val_one_hot_labels)\n",
    "    # Test set\n",
    "    h5file.create_dataset('test_x', data=skes_joints[test_indices])\n",
    "    test_one_hot_labels = one_hot_vector(test_labels)\n",
    "    h5file.create_dataset('test_y', data=test_one_hot_labels)\n",
    "\n",
    "    h5file.close()\n",
    "\n",
    "\n",
    "def get_indices(performer, camera, evaluation='CS'):\n",
    "    test_indices = np.empty(0)\n",
    "    train_indices = np.empty(0)\n",
    "\n",
    "    if evaluation == 'CS':  # Cross Subject (Subject IDs)\n",
    "        train_ids = [1,  2,  4,  5,  8,  9,  13, 14, 15, 16,\n",
    "                     17, 18, 19, 25, 27, 28, 31, 34, 35, 38]\n",
    "        test_ids = [3,  6,  7,  10, 11, 12, 20, 21, 22, 23,\n",
    "                    24, 26, 29, 30, 32, 33, 36, 37, 39, 40]\n",
    "\n",
    "        # Get indices of test data\n",
    "        for idx in test_ids:\n",
    "            temp = np.where(performer == idx)[0]  # 0-based index\n",
    "            test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
    "\n",
    "        # Get indices of training data\n",
    "        for train_id in train_ids:\n",
    "            temp = np.where(performer == train_id)[0]  # 0-based index\n",
    "            train_indices = np.hstack((train_indices, temp)).astype(np.int)\n",
    "    else:  # Cross View (Camera IDs)\n",
    "        train_ids = [2, 3]\n",
    "        test_ids = 1\n",
    "        # Get indices of test data\n",
    "        temp = np.where(camera == test_ids)[0]  # 0-based index\n",
    "        test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
    "\n",
    "        # Get indices of training data\n",
    "        for train_id in train_ids:\n",
    "            temp = np.where(camera == train_id)[0]  # 0-based index\n",
    "            train_indices = np.hstack((train_indices, temp)).astype(np.int)\n",
    "\n",
    "    return train_indices, test_indices\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    camera = np.loadtxt(camera_file, dtype=np.int)  # camera id: 1, 2, 3\n",
    "    performer = np.loadtxt(performer_file, dtype=np.int)  # subject id: 1~40\n",
    "    label = np.loadtxt(label_file, dtype=np.int) - 1  # action label: 0~59\n",
    "\n",
    "    frames_cnt = np.loadtxt(frames_file, dtype=np.int)  # frames_cnt\n",
    "    skes_name = np.loadtxt(skes_name_file, dtype=np.string_)\n",
    "\n",
    "    with open(raw_skes_joints_pkl, 'rb') as fr:\n",
    "        skes_joints = pickle.load(fr)  # a list\n",
    "\n",
    "    skes_joints = seq_translation(skes_joints)\n",
    "\n",
    "    skes_joints = align_frames(skes_joints, frames_cnt)  # aligned to the same frame length\n",
    "\n",
    "    evaluations = ['CS', 'CV']\n",
    "    for evaluation in evaluations:\n",
    "        split_dataset(skes_joints, label, performer, camera, evaluation, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
