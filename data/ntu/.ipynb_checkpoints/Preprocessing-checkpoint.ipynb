{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting raw bodies data from a skeleton sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "\n",
    "def get_raw_bodies_data(skes_path, ske_name, frames_drop_skes, frames_drop_logger):\n",
    "    \"\"\"\n",
    "    Get raw bodies data from a skeleton sequence.\n",
    "    Each body's data is a dict that contains the following keys:\n",
    "      - joints: raw 3D joints positions. Shape: (num_frames x 25, 3)\n",
    "      - colors: raw 2D color locations. Shape: (num_frames, 25, 2)\n",
    "      - interval: a list which stores the frame indices of this body.\n",
    "      - motion: motion amount (only for the sequence with 2 or more bodyIDs).\n",
    "\n",
    "    Return:\n",
    "      a dict for a skeleton sequence with 3 key-value pairs:\n",
    "        - name: the skeleton filename.\n",
    "        - data: a dict which stores raw data of each body.\n",
    "        - num_frames: the number of valid frames.\n",
    "    \"\"\"\n",
    "    ske_file = osp.join(skes_path, ske_name + '.skeleton')\n",
    "    assert osp.exists(ske_file), 'Error: Skeleton file %s not found' % ske_file\n",
    "    # Read all data from .skeleton file into a list (in string format)\n",
    "    print('Reading data from %s' % ske_file[-29:])\n",
    "    with open(ske_file, 'r') as fr:\n",
    "        str_data = fr.readlines()\n",
    "\n",
    "    num_frames = int(str_data[0].strip('\\r\\n'))\n",
    "    frames_drop = []\n",
    "    bodies_data = dict()\n",
    "    valid_frames = -1  # 0-based index\n",
    "    current_line = 1\n",
    "\n",
    "    for f in range(num_frames):\n",
    "        num_bodies = int(str_data[current_line].strip('\\r\\n'))\n",
    "        current_line += 1\n",
    "\n",
    "        if num_bodies == 0:  # no data in this frame, drop it\n",
    "            frames_drop.append(f)  # 0-based index\n",
    "            continue\n",
    "\n",
    "        valid_frames += 1\n",
    "        joints = np.zeros((num_bodies, 25, 3), dtype=np.float32)\n",
    "        colors = np.zeros((num_bodies, 25, 2), dtype=np.float32)\n",
    "\n",
    "        for b in range(num_bodies):\n",
    "            bodyID = str_data[current_line].strip('\\r\\n').split()[0]\n",
    "            current_line += 1\n",
    "            num_joints = int(str_data[current_line].strip('\\r\\n'))  # 25 joints\n",
    "            current_line += 1\n",
    "\n",
    "            for j in range(num_joints):\n",
    "                temp_str = str_data[current_line].strip('\\r\\n').split()\n",
    "                joints[b, j, :] = np.array(temp_str[:3], dtype=np.float32)\n",
    "                colors[b, j, :] = np.array(temp_str[5:7], dtype=np.float32)\n",
    "                current_line += 1\n",
    "\n",
    "            if bodyID not in bodies_data:  # Add a new body's data\n",
    "                body_data = dict()\n",
    "                body_data['joints'] = joints[b]  # ndarray: (25, 3)\n",
    "                body_data['colors'] = colors[b, np.newaxis]  # ndarray: (1, 25, 2)\n",
    "                body_data['interval'] = [valid_frames]  # the index of the first frame\n",
    "            else:  # Update an already existed body's data\n",
    "                body_data = bodies_data[bodyID]\n",
    "                # Stack each body's data of each frame along the frame order\n",
    "                body_data['joints'] = np.vstack((body_data['joints'], joints[b]))\n",
    "                body_data['colors'] = np.vstack((body_data['colors'], colors[b, np.newaxis]))\n",
    "                pre_frame_idx = body_data['interval'][-1]\n",
    "                body_data['interval'].append(pre_frame_idx + 1)  # add a new frame index\n",
    "\n",
    "            bodies_data[bodyID] = body_data  # Update bodies_data\n",
    "\n",
    "    num_frames_drop = len(frames_drop)\n",
    "    assert num_frames_drop < num_frames, \\\n",
    "        'Error: All frames data (%d) of %s is missing or lost' % (num_frames, ske_name)\n",
    "    if num_frames_drop > 0:\n",
    "        frames_drop_skes[ske_name] = np.array(frames_drop, dtype=np.int)\n",
    "        frames_drop_logger.info('{}: {} frames missed: {}\\n'.format(ske_name, num_frames_drop,\n",
    "                                                                    frames_drop))\n",
    "\n",
    "    # Calculate motion (only for the sequence with 2 or more bodyIDs)\n",
    "    if len(bodies_data) > 1:\n",
    "        for body_data in bodies_data.values():\n",
    "            body_data['motion'] = np.sum(np.var(body_data['joints'], axis=0))\n",
    "\n",
    "    return {'name': ske_name, 'data': bodies_data, 'num_frames': num_frames - num_frames_drop}\n",
    "\n",
    "\n",
    "def get_raw_skes_data():\n",
    "    # # save_path = './data'\n",
    "    # # skes_path = '/data/pengfei/NTU/nturgb+d_skeletons/'\n",
    "    # stat_path = osp.join(save_path, 'statistics')\n",
    "    #\n",
    "    # skes_name_file = osp.join(stat_path, 'skes_available_name.txt')\n",
    "    # save_data_pkl = osp.join(save_path, 'raw_skes_data.pkl')\n",
    "    # frames_drop_pkl = osp.join(save_path, 'frames_drop_skes.pkl')\n",
    "    #\n",
    "    # frames_drop_logger = logging.getLogger('frames_drop')\n",
    "    # frames_drop_logger.setLevel(logging.INFO)\n",
    "    # frames_drop_logger.addHandler(logging.FileHandler(osp.join(save_path, 'frames_drop.log')))\n",
    "    # frames_drop_skes = dict()\n",
    "\n",
    "    skes_name = np.loadtxt(skes_name_file, dtype=str)\n",
    "\n",
    "    num_files = skes_name.size\n",
    "    print('Found %d available skeleton files.' % num_files)\n",
    "\n",
    "    raw_skes_data = []\n",
    "    frames_cnt = np.zeros(num_files, dtype=np.int)\n",
    "\n",
    "    for (idx, ske_name) in enumerate(skes_name):\n",
    "        bodies_data = get_raw_bodies_data(skes_path, ske_name, frames_drop_skes, frames_drop_logger)\n",
    "        raw_skes_data.append(bodies_data)\n",
    "        frames_cnt[idx] = bodies_data['num_frames']\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print('Processed: %.2f%% (%d / %d)' % \\\n",
    "                  (100.0 * (idx + 1) / num_files, idx + 1, num_files))\n",
    "\n",
    "    with open(save_data_pkl, 'wb') as fw:\n",
    "        pickle.dump(raw_skes_data, fw, pickle.HIGHEST_PROTOCOL)\n",
    "    np.savetxt(osp.join(save_path, 'raw_data', 'frames_cnt.txt'), frames_cnt, fmt='%d')\n",
    "\n",
    "    print('Saved raw bodies data into %s' % save_data_pkl)\n",
    "    print('Total frames: %d' % np.sum(frames_cnt))\n",
    "\n",
    "    with open(frames_drop_pkl, 'wb') as fw:\n",
    "        pickle.dump(frames_drop_skes, fw, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    save_path = './'\n",
    "\n",
    "    skes_path = './nturgb+d_skeletons/'\n",
    "    stat_path = osp.join(save_path, 'statistics')\n",
    "    if not osp.exists('./raw_data'):\n",
    "        os.makedirs('./raw_data')\n",
    "\n",
    "    skes_name_file = osp.join(stat_path, 'skes_available_name.txt')\n",
    "    save_data_pkl = osp.join(save_path, 'raw_data', 'raw_skes_data.pkl')\n",
    "    frames_drop_pkl = osp.join(save_path, 'raw_data', 'frames_drop_skes.pkl')\n",
    "\n",
    "    frames_drop_logger = logging.getLogger('frames_drop')\n",
    "    frames_drop_logger.setLevel(logging.INFO)\n",
    "    frames_drop_logger.addHandler(logging.FileHandler(osp.join(save_path, 'raw_data', 'frames_drop.log')))\n",
    "    frames_drop_skes = dict()\n",
    "\n",
    "    get_raw_skes_data()\n",
    "\n",
    "    with open(frames_drop_pkl, 'wb') as fw:\n",
    "        pickle.dump(frames_drop_skes, fw, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting denoised data (joints positions and color locations) from raw skeleton sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "root_path = './'\n",
    "raw_data_file = osp.join(root_path, 'raw_data', 'raw_skes_data.pkl')\n",
    "save_path = osp.join(root_path, 'denoised_data')\n",
    "\n",
    "if not osp.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "rgb_ske_path = osp.join(save_path, 'rgb+ske')\n",
    "if not osp.exists(rgb_ske_path):\n",
    "    os.mkdir(rgb_ske_path)\n",
    "\n",
    "actors_info_dir = osp.join(save_path, 'actors_info')\n",
    "if not osp.exists(actors_info_dir):\n",
    "    os.mkdir(actors_info_dir)\n",
    "\n",
    "missing_count = 0\n",
    "noise_len_thres = 11\n",
    "noise_spr_thres1 = 0.8\n",
    "noise_spr_thres2 = 0.69754\n",
    "noise_mot_thres_lo = 0.089925\n",
    "noise_mot_thres_hi = 2\n",
    "\n",
    "noise_len_logger = logging.getLogger('noise_length')\n",
    "noise_len_logger.setLevel(logging.INFO)\n",
    "noise_len_logger.addHandler(logging.FileHandler(osp.join(save_path, 'noise_length.log')))\n",
    "noise_len_logger.info('{:^20}\\t{:^17}\\t{:^8}\\t{}'.format('Skeleton', 'bodyID', 'Motion', 'Length'))\n",
    "\n",
    "noise_spr_logger = logging.getLogger('noise_spread')\n",
    "noise_spr_logger.setLevel(logging.INFO)\n",
    "noise_spr_logger.addHandler(logging.FileHandler(osp.join(save_path, 'noise_spread.log')))\n",
    "noise_spr_logger.info('{:^20}\\t{:^17}\\t{:^8}\\t{:^8}'.format('Skeleton', 'bodyID', 'Motion', 'Rate'))\n",
    "\n",
    "noise_mot_logger = logging.getLogger('noise_motion')\n",
    "noise_mot_logger.setLevel(logging.INFO)\n",
    "noise_mot_logger.addHandler(logging.FileHandler(osp.join(save_path, 'noise_motion.log')))\n",
    "noise_mot_logger.info('{:^20}\\t{:^17}\\t{:^8}'.format('Skeleton', 'bodyID', 'Motion'))\n",
    "\n",
    "fail_logger_1 = logging.getLogger('noise_outliers_1')\n",
    "fail_logger_1.setLevel(logging.INFO)\n",
    "fail_logger_1.addHandler(logging.FileHandler(osp.join(save_path, 'denoised_failed_1.log')))\n",
    "\n",
    "fail_logger_2 = logging.getLogger('noise_outliers_2')\n",
    "fail_logger_2.setLevel(logging.INFO)\n",
    "fail_logger_2.addHandler(logging.FileHandler(osp.join(save_path, 'denoised_failed_2.log')))\n",
    "\n",
    "missing_skes_logger = logging.getLogger('missing_frames')\n",
    "missing_skes_logger.setLevel(logging.INFO)\n",
    "missing_skes_logger.addHandler(logging.FileHandler(osp.join(save_path, 'missing_skes.log')))\n",
    "missing_skes_logger.info('{:^20}\\t{}\\t{}'.format('Skeleton', 'num_frames', 'num_missing'))\n",
    "\n",
    "missing_skes_logger1 = logging.getLogger('missing_frames_1')\n",
    "missing_skes_logger1.setLevel(logging.INFO)\n",
    "missing_skes_logger1.addHandler(logging.FileHandler(osp.join(save_path, 'missing_skes_1.log')))\n",
    "missing_skes_logger1.info('{:^20}\\t{}\\t{}\\t{}\\t{}\\t{}'.format('Skeleton', 'num_frames', 'Actor1',\n",
    "                                                              'Actor2', 'Start', 'End'))\n",
    "\n",
    "missing_skes_logger2 = logging.getLogger('missing_frames_2')\n",
    "missing_skes_logger2.setLevel(logging.INFO)\n",
    "missing_skes_logger2.addHandler(logging.FileHandler(osp.join(save_path, 'missing_skes_2.log')))\n",
    "missing_skes_logger2.info('{:^20}\\t{}\\t{}\\t{}'.format('Skeleton', 'num_frames', 'Actor1', 'Actor2'))\n",
    "\n",
    "\n",
    "def denoising_by_length(ske_name, bodies_data):\n",
    "    \"\"\"\n",
    "    Denoising data based on the frame length for each bodyID.\n",
    "    Filter out the bodyID which length is less or equal than the predefined threshold.\n",
    "\n",
    "    \"\"\"\n",
    "    noise_info = str()\n",
    "    new_bodies_data = bodies_data.copy()\n",
    "    for (bodyID, body_data) in new_bodies_data.items():\n",
    "        length = len(body_data['interval'])\n",
    "        if length <= noise_len_thres:\n",
    "            noise_info += 'Filter out: %s, %d (length).\\n' % (bodyID, length)\n",
    "            noise_len_logger.info('{}\\t{}\\t{:.6f}\\t{:^6d}'.format(ske_name, bodyID,\n",
    "                                                                  body_data['motion'], length))\n",
    "            del bodies_data[bodyID]\n",
    "    if noise_info != '':\n",
    "        noise_info += '\\n'\n",
    "\n",
    "    return bodies_data, noise_info\n",
    "\n",
    "\n",
    "def get_valid_frames_by_spread(points):\n",
    "    \"\"\"\n",
    "    Find the valid (or reasonable) frames (index) based on the spread of X and Y.\n",
    "\n",
    "    :param points: joints or colors\n",
    "    \"\"\"\n",
    "    num_frames = points.shape[0]\n",
    "    valid_frames = []\n",
    "    for i in range(num_frames):\n",
    "        x = points[i, :, 0]\n",
    "        y = points[i, :, 1]\n",
    "        if (x.max() - x.min()) <= noise_spr_thres1 * (y.max() - y.min()):  # 0.8\n",
    "            valid_frames.append(i)\n",
    "    return valid_frames\n",
    "\n",
    "\n",
    "def denoising_by_spread(ske_name, bodies_data):\n",
    "    \"\"\"\n",
    "    Denoising data based on the spread of Y value and X value.\n",
    "    Filter out the bodyID which the ratio of noisy frames is higher than the predefined\n",
    "    threshold.\n",
    "\n",
    "    bodies_data: contains at least 2 bodyIDs\n",
    "    \"\"\"\n",
    "    noise_info = str()\n",
    "    denoised_by_spr = False  # mark if this sequence has been processed by spread.\n",
    "\n",
    "    new_bodies_data = bodies_data.copy()\n",
    "    # for (bodyID, body_data) in bodies_data.items():\n",
    "    for (bodyID, body_data) in new_bodies_data.items():\n",
    "        if len(bodies_data) == 1:\n",
    "            break\n",
    "        valid_frames = get_valid_frames_by_spread(body_data['joints'].reshape(-1, 25, 3))\n",
    "        num_frames = len(body_data['interval'])\n",
    "        num_noise = num_frames - len(valid_frames)\n",
    "        if num_noise == 0:\n",
    "            continue\n",
    "\n",
    "        ratio = num_noise / float(num_frames)\n",
    "        motion = body_data['motion']\n",
    "        if ratio >= noise_spr_thres2:  # 0.69754\n",
    "            del bodies_data[bodyID]\n",
    "            denoised_by_spr = True\n",
    "            noise_info += 'Filter out: %s (spread rate >= %.2f).\\n' % (bodyID, noise_spr_thres2)\n",
    "            noise_spr_logger.info('%s\\t%s\\t%.6f\\t%.6f' % (ske_name, bodyID, motion, ratio))\n",
    "        else:  # Update motion\n",
    "            joints = body_data['joints'].reshape(-1, 25, 3)[valid_frames]\n",
    "            body_data['motion'] = min(motion, np.sum(np.var(joints.reshape(-1, 3), axis=0)))\n",
    "            noise_info += '%s: motion %.6f -> %.6f\\n' % (bodyID, motion, body_data['motion'])\n",
    "            # TODO: Consider removing noisy frames for each bodyID\n",
    "\n",
    "    if noise_info != '':\n",
    "        noise_info += '\\n'\n",
    "\n",
    "    return bodies_data, noise_info, denoised_by_spr\n",
    "\n",
    "\n",
    "def denoising_by_motion(ske_name, bodies_data, bodies_motion):\n",
    "    \"\"\"\n",
    "    Filter out the bodyID which motion is out of the range of predefined interval\n",
    "\n",
    "    \"\"\"\n",
    "    # Sort bodies based on the motion, return a list of tuples\n",
    "    # bodies_motion = sorted(bodies_motion.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True)\n",
    "    bodies_motion = sorted(bodies_motion.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Reserve the body data with the largest motion\n",
    "    denoised_bodies_data = [(bodies_motion[0][0], bodies_data[bodies_motion[0][0]])]\n",
    "    noise_info = str()\n",
    "\n",
    "    for (bodyID, motion) in bodies_motion[1:]:\n",
    "        if (motion < noise_mot_thres_lo) or (motion > noise_mot_thres_hi):\n",
    "            noise_info += 'Filter out: %s, %.6f (motion).\\n' % (bodyID, motion)\n",
    "            noise_mot_logger.info('{}\\t{}\\t{:.6f}'.format(ske_name, bodyID, motion))\n",
    "        else:\n",
    "            denoised_bodies_data.append((bodyID, bodies_data[bodyID]))\n",
    "    if noise_info != '':\n",
    "        noise_info += '\\n'\n",
    "\n",
    "    return denoised_bodies_data, noise_info\n",
    "\n",
    "\n",
    "def denoising_bodies_data(bodies_data):\n",
    "    \"\"\"\n",
    "    Denoising data based on some heuristic methods, not necessarily correct for all samples.\n",
    "\n",
    "    Return:\n",
    "      denoised_bodies_data (list): tuple: (bodyID, body_data).\n",
    "    \"\"\"\n",
    "    ske_name = bodies_data['name']\n",
    "    bodies_data = bodies_data['data']\n",
    "\n",
    "    # Step 1: Denoising based on frame length.\n",
    "    bodies_data, noise_info_len = denoising_by_length(ske_name, bodies_data)\n",
    "\n",
    "    if len(bodies_data) == 1:  # only has one bodyID left after step 1\n",
    "        return bodies_data.items(), noise_info_len\n",
    "\n",
    "    # Step 2: Denoising based on spread.\n",
    "    bodies_data, noise_info_spr, denoised_by_spr = denoising_by_spread(ske_name, bodies_data)\n",
    "\n",
    "    if len(bodies_data) == 1:\n",
    "        return bodies_data.items(), noise_info_len + noise_info_spr\n",
    "\n",
    "    bodies_motion = dict()  # get body motion\n",
    "    for (bodyID, body_data) in bodies_data.items():\n",
    "        bodies_motion[bodyID] = body_data['motion']\n",
    "    # Sort bodies based on the motion\n",
    "    # bodies_motion = sorted(bodies_motion.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True)\n",
    "    bodies_motion = sorted(bodies_motion.items(), key=lambda x: x[1], reverse=True)\n",
    "    denoised_bodies_data = list()\n",
    "    for (bodyID, _) in bodies_motion:\n",
    "        denoised_bodies_data.append((bodyID, bodies_data[bodyID]))\n",
    "\n",
    "    return denoised_bodies_data, noise_info_len + noise_info_spr\n",
    "\n",
    "    # TODO: Consider denoising further by integrating motion method\n",
    "\n",
    "    # if denoised_by_spr:  # this sequence has been denoised by spread\n",
    "    #     bodies_motion = sorted(bodies_motion.items(), lambda x, y: cmp(x[1], y[1]), reverse=True)\n",
    "    #     denoised_bodies_data = list()\n",
    "    #     for (bodyID, _) in bodies_motion:\n",
    "    #         denoised_bodies_data.append((bodyID, bodies_data[bodyID]))\n",
    "    #     return denoised_bodies_data, noise_info\n",
    "\n",
    "    # Step 3: Denoising based on motion\n",
    "    # bodies_data, noise_info = denoising_by_motion(ske_name, bodies_data, bodies_motion)\n",
    "\n",
    "    # return bodies_data, noise_info\n",
    "\n",
    "\n",
    "def get_one_actor_points(body_data, num_frames):\n",
    "    \"\"\"\n",
    "    Get joints and colors for only one actor.\n",
    "    For joints, each frame contains 75 X-Y-Z coordinates.\n",
    "    For colors, each frame contains 25 x 2 (X, Y) coordinates.\n",
    "    \"\"\"\n",
    "    joints = np.zeros((num_frames, 75), dtype=np.float32)\n",
    "    colors = np.ones((num_frames, 1, 25, 2), dtype=np.float32) * np.nan\n",
    "    start, end = body_data['interval'][0], body_data['interval'][-1]\n",
    "    joints[start:end + 1] = body_data['joints'].reshape(-1, 75)\n",
    "    colors[start:end + 1, 0] = body_data['colors']\n",
    "\n",
    "    return joints, colors\n",
    "\n",
    "\n",
    "def remove_missing_frames(ske_name, joints, colors):\n",
    "    \"\"\"\n",
    "    Cut off missing frames which all joints positions are 0s\n",
    "\n",
    "    For the sequence with 2 actors' data, also record the number of missing frames for\n",
    "    actor1 and actor2, respectively (for debug).\n",
    "    \"\"\"\n",
    "    num_frames = joints.shape[0]\n",
    "    num_bodies = colors.shape[1]  # 1 or 2\n",
    "\n",
    "    if num_bodies == 2:  # DEBUG\n",
    "        missing_indices_1 = np.where(joints[:, :75].sum(axis=1) == 0)[0]\n",
    "        missing_indices_2 = np.where(joints[:, 75:].sum(axis=1) == 0)[0]\n",
    "        cnt1 = len(missing_indices_1)\n",
    "        cnt2 = len(missing_indices_2)\n",
    "\n",
    "        start = 1 if 0 in missing_indices_1 else 0\n",
    "        end = 1 if num_frames - 1 in missing_indices_1 else 0\n",
    "        if max(cnt1, cnt2) > 0:\n",
    "            if cnt1 > cnt2:\n",
    "                info = '{}\\t{:^10d}\\t{:^6d}\\t{:^6d}\\t{:^5d}\\t{:^3d}'.format(ske_name, num_frames,\n",
    "                                                                            cnt1, cnt2, start, end)\n",
    "                missing_skes_logger1.info(info)\n",
    "            else:\n",
    "                info = '{}\\t{:^10d}\\t{:^6d}\\t{:^6d}'.format(ske_name, num_frames, cnt1, cnt2)\n",
    "                missing_skes_logger2.info(info)\n",
    "\n",
    "    # Find valid frame indices that the data is not missing or lost\n",
    "    # For two-subjects action, this means both data of actor1 and actor2 is missing.\n",
    "    valid_indices = np.where(joints.sum(axis=1) != 0)[0]  # 0-based index\n",
    "    missing_indices = np.where(joints.sum(axis=1) == 0)[0]\n",
    "    num_missing = len(missing_indices)\n",
    "\n",
    "    if num_missing > 0:  # Update joints and colors\n",
    "        joints = joints[valid_indices]\n",
    "        colors[missing_indices] = np.nan\n",
    "        global missing_count\n",
    "        missing_count += 1\n",
    "        missing_skes_logger.info('{}\\t{:^10d}\\t{:^11d}'.format(ske_name, num_frames, num_missing))\n",
    "\n",
    "    return joints, colors\n",
    "\n",
    "\n",
    "def get_bodies_info(bodies_data):\n",
    "    bodies_info = '{:^17}\\t{}\\t{:^8}\\n'.format('bodyID', 'Interval', 'Motion')\n",
    "    for (bodyID, body_data) in bodies_data.items():\n",
    "        start, end = body_data['interval'][0], body_data['interval'][-1]\n",
    "        bodies_info += '{}\\t{:^8}\\t{:f}\\n'.format(bodyID, str([start, end]), body_data['motion'])\n",
    "\n",
    "    return bodies_info + '\\n'\n",
    "\n",
    "\n",
    "def get_two_actors_points(bodies_data):\n",
    "    \"\"\"\n",
    "    Get the first and second actor's joints positions and colors locations.\n",
    "\n",
    "    # Arguments:\n",
    "        bodies_data (dict): 3 key-value pairs: 'name', 'data', 'num_frames'.\n",
    "        bodies_data['data'] is also a dict, while the key is bodyID, the value is\n",
    "        the corresponding body_data which is also a dict with 4 keys:\n",
    "          - joints: raw 3D joints positions. Shape: (num_frames x 25, 3)\n",
    "          - colors: raw 2D color locations. Shape: (num_frames, 25, 2)\n",
    "          - interval: a list which records the frame indices.\n",
    "          - motion: motion amount\n",
    "\n",
    "    # Return:\n",
    "        joints, colors.\n",
    "    \"\"\"\n",
    "    ske_name = bodies_data['name']\n",
    "    label = int(ske_name[-2:])\n",
    "    num_frames = bodies_data['num_frames']\n",
    "    bodies_info = get_bodies_info(bodies_data['data'])\n",
    "\n",
    "    bodies_data, noise_info = denoising_bodies_data(bodies_data)  # Denoising data\n",
    "    bodies_info += noise_info\n",
    "\n",
    "    bodies_data = list(bodies_data)\n",
    "    if len(bodies_data) == 1:  # Only left one actor after denoising\n",
    "        if label >= 50:  # DEBUG: Denoising failed for two-subjects action\n",
    "            fail_logger_2.info(ske_name)\n",
    "\n",
    "        bodyID, body_data = bodies_data[0]\n",
    "        joints, colors = get_one_actor_points(body_data, num_frames)\n",
    "        bodies_info += 'Main actor: %s' % bodyID\n",
    "    else:\n",
    "        if label < 50:  # DEBUG: Denoising failed for one-subject action\n",
    "            fail_logger_1.info(ske_name)\n",
    "\n",
    "        joints = np.zeros((num_frames, 150), dtype=np.float32)\n",
    "        colors = np.ones((num_frames, 2, 25, 2), dtype=np.float32) * np.nan\n",
    "\n",
    "        bodyID, actor1 = bodies_data[0]  # the 1st actor with largest motion\n",
    "        start1, end1 = actor1['interval'][0], actor1['interval'][-1]\n",
    "        joints[start1:end1 + 1, :75] = actor1['joints'].reshape(-1, 75)\n",
    "        colors[start1:end1 + 1, 0] = actor1['colors']\n",
    "        actor1_info = '{:^17}\\t{}\\t{:^8}\\n'.format('Actor1', 'Interval', 'Motion') + \\\n",
    "                      '{}\\t{:^8}\\t{:f}\\n'.format(bodyID, str([start1, end1]), actor1['motion'])\n",
    "        del bodies_data[0]\n",
    "\n",
    "        actor2_info = '{:^17}\\t{}\\t{:^8}\\n'.format('Actor2', 'Interval', 'Motion')\n",
    "        start2, end2 = [0, 0]  # initial interval for actor2 (virtual)\n",
    "\n",
    "        while len(bodies_data) > 0:\n",
    "            bodyID, actor = bodies_data[0]\n",
    "            start, end = actor['interval'][0], actor['interval'][-1]\n",
    "            if min(end1, end) - max(start1, start) <= 0:  # no overlap with actor1\n",
    "                joints[start:end + 1, :75] = actor['joints'].reshape(-1, 75)\n",
    "                colors[start:end + 1, 0] = actor['colors']\n",
    "                actor1_info += '{}\\t{:^8}\\t{:f}\\n'.format(bodyID, str([start, end]), actor['motion'])\n",
    "                # Update the interval of actor1\n",
    "                start1 = min(start, start1)\n",
    "                end1 = max(end, end1)\n",
    "            elif min(end2, end) - max(start2, start) <= 0:  # no overlap with actor2\n",
    "                joints[start:end + 1, 75:] = actor['joints'].reshape(-1, 75)\n",
    "                colors[start:end + 1, 1] = actor['colors']\n",
    "                actor2_info += '{}\\t{:^8}\\t{:f}\\n'.format(bodyID, str([start, end]), actor['motion'])\n",
    "                # Update the interval of actor2\n",
    "                start2 = min(start, start2)\n",
    "                end2 = max(end, end2)\n",
    "            del bodies_data[0]\n",
    "\n",
    "        bodies_info += ('\\n' + actor1_info + '\\n' + actor2_info)\n",
    "\n",
    "    with open(osp.join(actors_info_dir, ske_name + '.txt'), 'w') as fw:\n",
    "        fw.write(bodies_info + '\\n')\n",
    "\n",
    "    return joints, colors\n",
    "\n",
    "\n",
    "def get_raw_denoised_data():\n",
    "    \"\"\"\n",
    "    Get denoised data (joints positions and color locations) from raw skeleton sequences.\n",
    "\n",
    "    For each frame of a skeleton sequence, an actor's 3D positions of 25 joints represented\n",
    "    by an 2D array (shape: 25 x 3) is reshaped into a 75-dim vector by concatenating each\n",
    "    3-dim (x, y, z) coordinates along the row dimension in joint order. Each frame contains\n",
    "    two actor's joints positions constituting a 150-dim vector. If there is only one actor,\n",
    "    then the last 75 values are filled with zeros. Otherwise, select the main actor and the\n",
    "    second actor based on the motion amount. Each 150-dim vector as a row vector is put into\n",
    "    a 2D numpy array where the number of rows equals the number of valid frames. All such\n",
    "    2D arrays are put into a list and finally the list is serialized into a cPickle file.\n",
    "\n",
    "    For the skeleton sequence which contains two or more actors (mostly corresponds to the\n",
    "    last 11 classes), the filename and actors' information are recorded into log files.\n",
    "    For better understanding, also generate RGB+skeleton videos for visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(raw_data_file, 'rb') as fr:  # load raw skeletons data\n",
    "        raw_skes_data = pickle.load(fr)\n",
    "\n",
    "    num_skes = len(raw_skes_data)\n",
    "    print('Found %d available skeleton sequences.' % num_skes)\n",
    "\n",
    "    raw_denoised_joints = []\n",
    "    raw_denoised_colors = []\n",
    "    frames_cnt = []\n",
    "\n",
    "    for (idx, bodies_data) in enumerate(raw_skes_data):\n",
    "        ske_name = bodies_data['name']\n",
    "        print('Processing %s' % ske_name)\n",
    "        num_bodies = len(bodies_data['data'])\n",
    "\n",
    "        if num_bodies == 1:  # only 1 actor\n",
    "            num_frames = bodies_data['num_frames']\n",
    "            body_data = list(bodies_data['data'].values())[0]\n",
    "            joints, colors = get_one_actor_points(body_data, num_frames)\n",
    "        else:  # more than 1 actor, select two main actors\n",
    "            joints, colors = get_two_actors_points(bodies_data)\n",
    "            # Remove missing frames\n",
    "            joints, colors = remove_missing_frames(ske_name, joints, colors)\n",
    "            num_frames = joints.shape[0]  # Update\n",
    "            # Visualize selected actors' skeletons on RGB videos.\n",
    "\n",
    "        raw_denoised_joints.append(joints)\n",
    "        raw_denoised_colors.append(colors)\n",
    "        frames_cnt.append(num_frames)\n",
    "\n",
    "        if (idx + 1) % 1000 == 0:\n",
    "            print('Processed: %.2f%% (%d / %d), ' % \\\n",
    "                  (100.0 * (idx + 1) / num_skes, idx + 1, num_skes) + \\\n",
    "                  'Missing count: %d' % missing_count)\n",
    "\n",
    "    raw_skes_joints_pkl = osp.join(save_path, 'raw_denoised_joints.pkl')\n",
    "    with open(raw_skes_joints_pkl, 'wb') as f:\n",
    "        pickle.dump(raw_denoised_joints, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    raw_skes_colors_pkl = osp.join(save_path, 'raw_denoised_colors.pkl')\n",
    "    with open(raw_skes_colors_pkl, 'wb') as f:\n",
    "        pickle.dump(raw_denoised_colors, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    frames_cnt = np.array(frames_cnt, dtype=np.int)\n",
    "    np.savetxt(osp.join(save_path, 'frames_cnt.txt'), frames_cnt, fmt='%d')\n",
    "\n",
    "    print('Saved raw denoised positions of {} frames into {}'.format(np.sum(frames_cnt),\n",
    "                                                                     raw_skes_joints_pkl))\n",
    "    print('Found %d files that have missing data' % missing_count)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    get_raw_denoised_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root_path = './'\n",
    "stat_path = osp.join(root_path, 'statistics')\n",
    "setup_file = osp.join(stat_path, 'setup.txt')\n",
    "camera_file = osp.join(stat_path, 'camera.txt')\n",
    "performer_file = osp.join(stat_path, 'performer.txt')\n",
    "replication_file = osp.join(stat_path, 'replication.txt')\n",
    "label_file = osp.join(stat_path, 'label.txt')\n",
    "skes_name_file = osp.join(stat_path, 'skes_available_name.txt')\n",
    "\n",
    "denoised_path = osp.join(root_path, 'denoised_data')\n",
    "raw_skes_joints_pkl = osp.join(denoised_path, 'raw_denoised_joints.pkl')\n",
    "frames_file = osp.join(denoised_path, 'frames_cnt.txt')\n",
    "\n",
    "save_path = './'\n",
    "\n",
    "\n",
    "if not osp.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "\n",
    "def remove_nan_frames(ske_name, ske_joints, nan_logger):\n",
    "    num_frames = ske_joints.shape[0]\n",
    "    valid_frames = []\n",
    "\n",
    "    for f in range(num_frames):\n",
    "        if not np.any(np.isnan(ske_joints[f])):\n",
    "            valid_frames.append(f)\n",
    "        else:\n",
    "            nan_indices = np.where(np.isnan(ske_joints[f]))[0]\n",
    "            nan_logger.info('{}\\t{:^5}\\t{}'.format(ske_name, f + 1, nan_indices))\n",
    "\n",
    "    return ske_joints[valid_frames]\n",
    "\n",
    "def seq_translation(skes_joints):\n",
    "    for idx, ske_joints in enumerate(skes_joints):\n",
    "        num_frames = ske_joints.shape[0]\n",
    "        num_bodies = 1 if ske_joints.shape[1] == 75 else 2\n",
    "        if num_bodies == 2:\n",
    "            missing_frames_1 = np.where(ske_joints[:, :75].sum(axis=1) == 0)[0]\n",
    "            missing_frames_2 = np.where(ske_joints[:, 75:].sum(axis=1) == 0)[0]\n",
    "            cnt1 = len(missing_frames_1)\n",
    "            cnt2 = len(missing_frames_2)\n",
    "\n",
    "        i = 0  # get the \"real\" first frame of actor1\n",
    "        while i < num_frames:\n",
    "            if np.any(ske_joints[i, :75] != 0):\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        origin = np.copy(ske_joints[i, 3:6])  # new origin: joint-2\n",
    "\n",
    "        for f in range(num_frames):\n",
    "            if num_bodies == 1:\n",
    "                ske_joints[f] -= np.tile(origin, 25)\n",
    "            else:  # for 2 actors\n",
    "                ske_joints[f] -= np.tile(origin, 50)\n",
    "\n",
    "        if (num_bodies == 2) and (cnt1 > 0):\n",
    "            ske_joints[missing_frames_1, :75] = np.zeros((cnt1, 75), dtype=np.float32)\n",
    "\n",
    "        if (num_bodies == 2) and (cnt2 > 0):\n",
    "            ske_joints[missing_frames_2, 75:] = np.zeros((cnt2, 75), dtype=np.float32)\n",
    "\n",
    "        skes_joints[idx] = ske_joints  # Update\n",
    "\n",
    "    return skes_joints\n",
    "\n",
    "\n",
    "def frame_translation(skes_joints, skes_name, frames_cnt):\n",
    "    nan_logger = logging.getLogger('nan_skes')\n",
    "    nan_logger.setLevel(logging.INFO)\n",
    "    nan_logger.addHandler(logging.FileHandler(\"./nan_frames.log\"))\n",
    "    nan_logger.info('{}\\t{}\\t{}'.format('Skeleton', 'Frame', 'Joints'))\n",
    "\n",
    "    for idx, ske_joints in enumerate(skes_joints):\n",
    "        num_frames = ske_joints.shape[0]\n",
    "        # Calculate the distance between spine base (joint-1) and spine (joint-21)\n",
    "        j1 = ske_joints[:, 0:3]\n",
    "        j21 = ske_joints[:, 60:63]\n",
    "        dist = np.sqrt(((j1 - j21) ** 2).sum(axis=1))\n",
    "\n",
    "        for f in range(num_frames):\n",
    "            origin = ske_joints[f, 3:6]  # new origin: middle of the spine (joint-2)\n",
    "            if (ske_joints[f, 75:] == 0).all():\n",
    "                ske_joints[f, :75] = (ske_joints[f, :75] - np.tile(origin, 25)) / \\\n",
    "                                      dist[f] + np.tile(origin, 25)\n",
    "            else:\n",
    "                ske_joints[f] = (ske_joints[f] - np.tile(origin, 50)) / \\\n",
    "                                 dist[f] + np.tile(origin, 50)\n",
    "\n",
    "        ske_name = skes_name[idx]\n",
    "        ske_joints = remove_nan_frames(ske_name, ske_joints, nan_logger)\n",
    "        frames_cnt[idx] = num_frames  # update valid number of frames\n",
    "        skes_joints[idx] = ske_joints\n",
    "\n",
    "    return skes_joints, frames_cnt\n",
    "\n",
    "\n",
    "def align_frames(skes_joints, frames_cnt):\n",
    "    \"\"\"\n",
    "    Align all sequences with the same frame length.\n",
    "\n",
    "    \"\"\"\n",
    "    num_skes = len(skes_joints)\n",
    "    max_num_frames = frames_cnt.max()  # 300\n",
    "    aligned_skes_joints = np.zeros((num_skes, max_num_frames, 150), dtype=np.float32)\n",
    "\n",
    "    for idx, ske_joints in enumerate(skes_joints):\n",
    "        num_frames = ske_joints.shape[0]\n",
    "        num_bodies = 1 if ske_joints.shape[1] == 75 else 2\n",
    "        if num_bodies == 1:\n",
    "            aligned_skes_joints[idx, :num_frames] = np.hstack((ske_joints,\n",
    "                                                               np.zeros_like(ske_joints)))\n",
    "        else:\n",
    "            aligned_skes_joints[idx, :num_frames] = ske_joints\n",
    "\n",
    "    return aligned_skes_joints\n",
    "\n",
    "\n",
    "def one_hot_vector(labels):\n",
    "    num_skes = len(labels)\n",
    "    labels_vector = np.zeros((num_skes, 60))\n",
    "    for idx, l in enumerate(labels):\n",
    "        labels_vector[idx, l] = 1\n",
    "\n",
    "    return labels_vector\n",
    "\n",
    "\n",
    "def split_train_val(train_indices, method='sklearn', ratio=0.05):\n",
    "    \"\"\"\n",
    "    Get validation set by splitting data randomly from training set with two methods.\n",
    "    In fact, I thought these two methods are equal as they got the same performance.\n",
    "\n",
    "    \"\"\"\n",
    "    if method == 'sklearn':\n",
    "        return train_test_split(train_indices, test_size=ratio, random_state=10000)\n",
    "    else:\n",
    "        np.random.seed(10000)\n",
    "        np.random.shuffle(train_indices)\n",
    "        val_num_skes = int(np.ceil(0.05 * len(train_indices)))\n",
    "        val_indices = train_indices[:val_num_skes]\n",
    "        train_indices = train_indices[val_num_skes:]\n",
    "        return train_indices, val_indices\n",
    "\n",
    "\n",
    "def split_dataset(skes_joints, label, performer, camera, evaluation, save_path):\n",
    "    train_indices, test_indices = get_indices(performer, camera, evaluation)\n",
    "    m = 'sklearn'  # 'sklearn' or 'numpy'\n",
    "    # Select validation set from training set\n",
    "    train_indices, val_indices = split_train_val(train_indices, m)\n",
    "\n",
    "    # Save labels and num_frames for each sequence of each data set\n",
    "    train_labels = label[train_indices]\n",
    "    val_labels = label[val_indices]\n",
    "    test_labels = label[test_indices]\n",
    "\n",
    "    # Save data into a .h5 file\n",
    "    h5file = h5py.File(osp.join(save_path, 'NTU_%s.h5' % (evaluation)), 'w')\n",
    "    # Training set\n",
    "    h5file.create_dataset('x', data=skes_joints[train_indices])\n",
    "    train_one_hot_labels = one_hot_vector(train_labels)\n",
    "    h5file.create_dataset('y', data=train_one_hot_labels)\n",
    "    # Validation set\n",
    "    h5file.create_dataset('valid_x', data=skes_joints[val_indices])\n",
    "    val_one_hot_labels = one_hot_vector(val_labels)\n",
    "    h5file.create_dataset('valid_y', data=val_one_hot_labels)\n",
    "    # Test set\n",
    "    h5file.create_dataset('test_x', data=skes_joints[test_indices])\n",
    "    test_one_hot_labels = one_hot_vector(test_labels)\n",
    "    h5file.create_dataset('test_y', data=test_one_hot_labels)\n",
    "\n",
    "    h5file.close()\n",
    "\n",
    "\n",
    "def get_indices(performer, camera, evaluation='CS'):\n",
    "    test_indices = np.empty(0)\n",
    "    train_indices = np.empty(0)\n",
    "\n",
    "    if evaluation == 'CS':  # Cross Subject (Subject IDs)\n",
    "        train_ids = [1,  2,  4,  5,  8,  9,  13, 14, 15, 16,\n",
    "                     17, 18, 19, 25, 27, 28, 31, 34, 35, 38]\n",
    "        test_ids = [3,  6,  7,  10, 11, 12, 20, 21, 22, 23,\n",
    "                    24, 26, 29, 30, 32, 33, 36, 37, 39, 40]\n",
    "\n",
    "        # Get indices of test data\n",
    "        for idx in test_ids:\n",
    "            temp = np.where(performer == idx)[0]  # 0-based index\n",
    "            test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
    "\n",
    "        # Get indices of training data\n",
    "        for train_id in train_ids:\n",
    "            temp = np.where(performer == train_id)[0]  # 0-based index\n",
    "            train_indices = np.hstack((train_indices, temp)).astype(np.int)\n",
    "    else:  # Cross View (Camera IDs)\n",
    "        train_ids = [2, 3]\n",
    "        test_ids = 1\n",
    "        # Get indices of test data\n",
    "        temp = np.where(camera == test_ids)[0]  # 0-based index\n",
    "        test_indices = np.hstack((test_indices, temp)).astype(np.int)\n",
    "\n",
    "        # Get indices of training data\n",
    "        for train_id in train_ids:\n",
    "            temp = np.where(camera == train_id)[0]  # 0-based index\n",
    "            train_indices = np.hstack((train_indices, temp)).astype(np.int)\n",
    "\n",
    "    return train_indices, test_indices\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    camera = np.loadtxt(camera_file, dtype=np.int)  # camera id: 1, 2, 3\n",
    "    performer = np.loadtxt(performer_file, dtype=np.int)  # subject id: 1~40\n",
    "    label = np.loadtxt(label_file, dtype=np.int) - 1  # action label: 0~59\n",
    "\n",
    "    frames_cnt = np.loadtxt(frames_file, dtype=np.int)  # frames_cnt\n",
    "    skes_name = np.loadtxt(skes_name_file, dtype=np.string_)\n",
    "\n",
    "    with open(raw_skes_joints_pkl, 'rb') as fr:\n",
    "        skes_joints = pickle.load(fr)  # a list\n",
    "\n",
    "    skes_joints = seq_translation(skes_joints)\n",
    "\n",
    "    skes_joints = align_frames(skes_joints, frames_cnt)  # aligned to the same frame length\n",
    "\n",
    "    evaluations = ['CS', 'CV']\n",
    "    for evaluation in evaluations:\n",
    "        split_dataset(skes_joints, label, performer, camera, evaluation, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
