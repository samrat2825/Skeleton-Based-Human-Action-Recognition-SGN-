{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import os.path as osp\n",
    "import sys\n",
    "from six.moves import xrange\n",
    "import math\n",
    "import scipy.misc\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTUDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = np.array(y, dtype='int')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [self.x[index], int(self.y[index])]\n",
    "\n",
    "class NTUDataLoaders(object):\n",
    "    def __init__(self, dataset ='NTU', case = 0, aug = 1, seg = 30):\n",
    "        self.dataset = dataset\n",
    "        self.case = case\n",
    "        self.aug = aug\n",
    "        self.seg = seg\n",
    "        self.create_datasets()\n",
    "        self.train_set = NTUDataset(self.train_X, self.train_Y)\n",
    "        self.val_set = NTUDataset(self.val_X, self.val_Y)\n",
    "        self.test_set = NTUDataset(self.test_X, self.test_Y)\n",
    "\n",
    "    def get_train_loader(self, batch_size, num_workers):\n",
    "        if self.aug == 0:\n",
    "            return DataLoader(self.train_set, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers,\n",
    "                              collate_fn=self.collate_fn_fix_val, pin_memory=False, drop_last=True)\n",
    "        elif self.aug ==1:\n",
    "            return DataLoader(self.train_set, batch_size=batch_size,\n",
    "                              shuffle=True, num_workers=num_workers,\n",
    "                              collate_fn=self.collate_fn_fix_train, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def get_val_loader(self, batch_size, num_workers):\n",
    "        if self.dataset == 'NTU' or self.dataset == 'kinetics' or self.dataset == 'NTU120':\n",
    "            return DataLoader(self.val_set, batch_size=batch_size,\n",
    "                              shuffle=False, num_workers=num_workers,\n",
    "                              collate_fn=self.collate_fn_fix_val, pin_memory=True, drop_last=True)\n",
    "        else:\n",
    "            return DataLoader(self.val_set, batch_size=batch_size,\n",
    "                              shuffle=False, num_workers=num_workers,\n",
    "                              collate_fn=self.collate_fn_fix_val, pin_memory=True, drop_last=True)\n",
    "\n",
    "\n",
    "    def get_test_loader(self, batch_size, num_workers):\n",
    "        return DataLoader(self.test_set, batch_size=batch_size,\n",
    "                          shuffle=False, num_workers=num_workers,\n",
    "                          collate_fn=self.collate_fn_fix_test, pin_memory=True, drop_last=True)\n",
    "\n",
    "    def get_train_size(self):\n",
    "        return len(self.train_Y)\n",
    "\n",
    "    def get_val_size(self):\n",
    "        return len(self.val_Y)\n",
    "\n",
    "    def get_test_size(self):\n",
    "        return len(self.test_Y)\n",
    "\n",
    "    def create_datasets(self):\n",
    "        if self.dataset == 'NTU':\n",
    "            if self.case ==0:\n",
    "                self.metric = 'CS'\n",
    "            elif self.case == 1:\n",
    "                self.metric = 'CV'\n",
    "            path = osp.join('./data/ntu', 'NTU_' + self.metric + '.h5')\n",
    "\n",
    "        f = h5py.File(path , 'r')\n",
    "        self.train_X = f['x'][:]\n",
    "        self.train_Y = np.argmax(f['y'][:],-1)\n",
    "        self.val_X = f['valid_x'][:]\n",
    "        self.val_Y = np.argmax(f['valid_y'][:], -1)\n",
    "        self.test_X = f['test_x'][:]\n",
    "        self.test_Y = np.argmax(f['test_y'][:], -1)\n",
    "        f.close()\n",
    "\n",
    "        ## Combine the training data and validation data togehter as ST-GCN\n",
    "        self.train_X = np.concatenate([self.train_X, self.val_X], axis=0)\n",
    "        self.train_Y = np.concatenate([self.train_Y, self.val_Y], axis=0)\n",
    "        self.val_X = self.test_X\n",
    "        self.val_Y = self.test_Y\n",
    "\n",
    "    def collate_fn_fix_train(self, batch):\n",
    "        \"\"\"Puts each data field into a tensor with outer dimension batch size\n",
    "        \"\"\"\n",
    "        x, y = zip(*batch)\n",
    "\n",
    "        if self.dataset == 'kinetics' and self.machine == 'philly':\n",
    "            x = np.array(x)\n",
    "            x = x.reshape(x.shape[0], x.shape[1],-1)\n",
    "            x = x.reshape(-1, x.shape[1] * x.shape[2], x.shape[3]*x.shape[4])\n",
    "            x = list(x)\n",
    "\n",
    "        x, y = self.Tolist_fix(x, y, train=1)\n",
    "        lens = np.array([x_.shape[0] for x_ in x], dtype=np.int)\n",
    "        idx = lens.argsort()[::-1]  # sort sequence by valid length in descending order\n",
    "        y = np.array(y)[idx]\n",
    "        x = torch.stack([torch.from_numpy(x[i]) for i in idx], 0)\n",
    "\n",
    "        if self.dataset == 'NTU':\n",
    "            if self.case == 0:\n",
    "                theta = 0.3\n",
    "            elif self.case == 1:\n",
    "                theta = 0.5\n",
    "        elif self.dataset == 'NTU120':\n",
    "            theta = 0.3\n",
    "\n",
    "        #### data augmentation\n",
    "        x = _transform(x, theta)\n",
    "        #### data augmentation\n",
    "        y = torch.LongTensor(y)\n",
    "\n",
    "        return [x, y]\n",
    "\n",
    "    def collate_fn_fix_val(self, batch):\n",
    "        \"\"\"Puts each data field into a tensor with outer dimension batch size\n",
    "        \"\"\"\n",
    "        x, y = zip(*batch)\n",
    "        x, y = self.Tolist_fix(x, y, train=1)\n",
    "        idx = range(len(x))\n",
    "        y = np.array(y)\n",
    "\n",
    "        x = torch.stack([torch.from_numpy(x[i]) for i in idx], 0)\n",
    "        y = torch.LongTensor(y)\n",
    "\n",
    "        return [x, y]\n",
    "\n",
    "    def collate_fn_fix_test(self, batch):\n",
    "        \"\"\"Puts each data field into a tensor with outer dimension batch size\n",
    "        \"\"\"\n",
    "        x, y = zip(*batch)\n",
    "        x, labels = self.Tolist_fix(x, y ,train=2)\n",
    "        idx = range(len(x))\n",
    "        y = np.array(y)\n",
    "\n",
    "\n",
    "        x = torch.stack([torch.from_numpy(x[i]) for i in idx], 0)\n",
    "        y = torch.LongTensor(y)\n",
    "\n",
    "        return [x, y]\n",
    "\n",
    "    def Tolist_fix(self, joints, y, train = 1):\n",
    "        seqs = []\n",
    "\n",
    "        for idx, seq in enumerate(joints):\n",
    "            zero_row = []\n",
    "            for i in range(len(seq)):\n",
    "                if (seq[i, :] == np.zeros((1, 150))).all():\n",
    "                        zero_row.append(i)\n",
    "\n",
    "            seq = np.delete(seq, zero_row, axis = 0)\n",
    "\n",
    "            seq = turn_two_to_one(seq)\n",
    "            seqs = self.sub_seq(seqs, seq, train=train)\n",
    "\n",
    "        return seqs, y\n",
    "\n",
    "    def sub_seq(self, seqs, seq , train = 1):\n",
    "        group = self.seg\n",
    "\n",
    "        if self.dataset == 'SYSU' or self.dataset == 'SYSU_same':\n",
    "            seq = seq[::2, :]\n",
    "\n",
    "        if seq.shape[0] < self.seg:\n",
    "            pad = np.zeros((self.seg - seq.shape[0], seq.shape[1])).astype(np.float32)\n",
    "            seq = np.concatenate([seq, pad], axis=0)\n",
    "\n",
    "        ave_duration = seq.shape[0] // group\n",
    "\n",
    "        if train == 1:\n",
    "            offsets = np.multiply(list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "            seq = seq[offsets]\n",
    "            seqs.append(seq)\n",
    "\n",
    "        elif train == 2:\n",
    "            offsets1 = np.multiply(list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "            offsets2 = np.multiply(list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "            offsets3 = np.multiply(list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "            offsets4 = np.multiply(list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "            offsets5 = np.multiply(list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "\n",
    "            seqs.append(seq[offsets1])\n",
    "            seqs.append(seq[offsets2])\n",
    "            seqs.append(seq[offsets3])\n",
    "            seqs.append(seq[offsets4])\n",
    "            seqs.append(seq[offsets5])\n",
    "\n",
    "        return seqs\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def turn_two_to_one(seq):\n",
    "    new_seq = list()\n",
    "    for idx, ske in enumerate(seq):\n",
    "        if (ske[0:75] == np.zeros((1, 75))).all():\n",
    "            new_seq.append(ske[75:])\n",
    "        elif (ske[75:] == np.zeros((1, 75))).all():\n",
    "            new_seq.append(ske[0:75])\n",
    "        else:\n",
    "            new_seq.append(ske[0:75])\n",
    "            new_seq.append(ske[75:])\n",
    "    return np.array(new_seq)\n",
    "\n",
    "def _rot(rot):\n",
    "    cos_r, sin_r = rot.cos(), rot.sin()\n",
    "    zeros = rot.new(rot.size()[:2] + (1,)).zero_()\n",
    "    ones = rot.new(rot.size()[:2] + (1,)).fill_(1)\n",
    "\n",
    "    r1 = torch.stack((ones, zeros, zeros),dim=-1)\n",
    "    rx2 = torch.stack((zeros, cos_r[:,:,0:1], sin_r[:,:,0:1]), dim = -1)\n",
    "    rx3 = torch.stack((zeros, -sin_r[:,:,0:1], cos_r[:,:,0:1]), dim = -1)\n",
    "    rx = torch.cat((r1, rx2, rx3), dim = 2)\n",
    "\n",
    "    ry1 = torch.stack((cos_r[:,:,1:2], zeros, -sin_r[:,:,1:2]), dim =-1)\n",
    "    r2 = torch.stack((zeros, ones, zeros),dim=-1)\n",
    "    ry3 = torch.stack((sin_r[:,:,1:2], zeros, cos_r[:,:,1:2]), dim =-1)\n",
    "    ry = torch.cat((ry1, r2, ry3), dim = 2)\n",
    "\n",
    "    rz1 = torch.stack((cos_r[:,:,2:3], sin_r[:,:,2:3], zeros), dim =-1)\n",
    "    r3 = torch.stack((zeros, zeros, ones),dim=-1)\n",
    "    rz2 = torch.stack((-sin_r[:,:,2:3], cos_r[:,:,2:3],zeros), dim =-1)\n",
    "    rz = torch.cat((rz1, rz2, r3), dim = 2)\n",
    "\n",
    "    rot = rz.matmul(ry).matmul(rx)\n",
    "    return rot\n",
    "\n",
    "def _transform(x, theta):\n",
    "    x = x.contiguous().view(x.size()[:2] + (-1, 3))\n",
    "    rot = x.new(x.size()[0],3).uniform_(-theta, theta)\n",
    "    rot = rot.repeat(1, x.size()[1])\n",
    "    rot = rot.contiguous().view((-1, x.size()[1], 3))\n",
    "    rot = _rot(rot)\n",
    "    x = torch.transpose(x, 2, 3)\n",
    "    x = torch.matmul(rot, x)\n",
    "    x = torch.transpose(x, 2, 3)\n",
    "\n",
    "    x = x.contiguous().view(x.size()[:2] + (-1,))\n",
    "    return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
